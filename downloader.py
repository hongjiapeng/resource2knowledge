# -*- coding: utf-8 -*-
"""
ğŸ¬ Video Downloader Module
ä½¿ç”¨ yt-dlp ä¸‹è½½è§†é¢‘éŸ³é¢‘
æ”¯æŒå°çº¢ä¹¦å›¾æ–‡ç¬”è®°æŠ“å–
"""

import os
import sys
import subprocess
import json
import re
import requests
from pathlib import Path
from typing import Optional, Dict


def get_yt_dlp_path() -> str:
    """è·å– yt-dlp è·¯å¾„"""
    # æ£€æŸ¥ venv ä¸­æ˜¯å¦æœ‰ yt-dlp
    venv_dir = Path(sys.executable).parent
    yt_dlp_venv = venv_dir / "yt-dlp.exe"
    if yt_dlp_venv.exists():
        return str(yt_dlp_venv)
    
    # å°è¯•ç›´æ¥è°ƒç”¨
    return "yt-dlp"


class VideoDownloader:
    """è§†é¢‘ä¸‹è½½å™¨ - ä»…ä¸‹è½½éŸ³é¢‘æµ"""
    
    # æ”¯æŒçš„å¹³å°åŸŸåæ˜ å°„
    PLATFORMS = {
        'youtube.com': 'YouTube',
        'youtu.be': 'YouTube',
        'bilibili.com': 'Bilibili',
        'b23.tv': 'Bilibili',
        'douyin.com': 'Douyin',
        'xiaohongshu.com': 'Xiaohongshu',
        'instagram.com': 'Instagram',
        'tiktok.com': 'TikTok',
        'x.com': 'X',
        'twitter.com': 'X',
    }
    
    def __init__(self, output_dir: str = "downloads"):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            output_dir: éŸ³é¢‘è¾“å‡ºç›®å½•
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def detect_platform(self, url: str) -> str:
        """æ£€æµ‹è§†é¢‘å¹³å°"""
        for domain, platform in self.PLATFORMS.items():
            if domain in url.lower():
                return platform
        return 'Unknown'
    
    def get_output_path(self, url: str, platform: str) -> Path:
        """ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„"""
        # ä½¿ç”¨ URL hash ä½œä¸ºæ–‡ä»¶åï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
        import hashlib
        url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
        
        # å°çº¢ä¹¦ç”¨ mp4ï¼Œå…¶ä»–ç”¨ m4a
        ext = 'mp4' if platform == 'Xiaohongshu' else 'm4a'
        return self.output_dir / f"{platform}_{url_hash}.{ext}"
    
    def download(self, url: str, force: bool = False) -> Dict:
        """
        ä¸‹è½½è§†é¢‘éŸ³é¢‘
        
        Args:
            url: è§†é¢‘é“¾æ¥
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            åŒ…å«éŸ³é¢‘è·¯å¾„ã€å¹³å°ã€è§†é¢‘æ ‡é¢˜çš„å­—å…¸
        """
        platform = self.detect_platform(url)
        output_path = self.get_output_path(url, platform)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶ä¸‹è½½ï¼Œç›´æ¥è¿”å›
        if output_path.exists() and not force:
            print(f"ğŸ“ æ–‡ä»¶å·²å­˜åœ¨: {output_path}")
            return {
                'audio_path': str(output_path),
                'platform': platform,
                'title': output_path.stem,
                'url': url
            }
        
        print(f"â¬‡ï¸ å¼€å§‹ä¸‹è½½: {url}")
        print(f"ğŸ“ å¹³å°: {platform}")
        
        yt_dlp = get_yt_dlp_path()
        
        # ========== å¹³å°ç‰¹å®šé…ç½® ==========
        if platform == 'Xiaohongshu':
            # å°çº¢ä¹¦ï¼šä¸‹è½½å®Œæ•´è§†é¢‘ï¼ˆä¿ç•™è§†é¢‘è½¨é“ï¼‰
            cmd = [
                yt_dlp,
                '-f', 'best',
                '--merge-output-format', 'mp4',
                '-o', str(output_path),
                url
            ]
        elif platform == 'Bilibili':
            # Bç«™ï¼šä¸‹è½½éŸ³é¢‘
            cmd = [
                yt_dlp,
                '-f', 'bestaudio',
                '--audio-format', 'm4a',
                '--audio-quality', '0',
                '-o', str(output_path),
                url
            ]
        else:
            # YouTube ç­‰å¹³å°ï¼šä¸‹è½½éŸ³é¢‘
            cmd = [
                yt_dlp,
                '-f', 'bestaudio',
                '--audio-format', 'm4a',
                '-o', str(output_path),
                '--no-playlist',
                url
            ]
        
        try:
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            if result.returncode != 0:
                raise Exception(f"ä¸‹è½½å¤±è´¥: {result.stderr}")
            
            # è·å–è§†é¢‘æ ‡é¢˜
            title = self._get_title(url) or output_path.stem
            
            print(f"âœ… ä¸‹è½½å®Œæˆ: {output_path.name}")
            
            return {
                'audio_path': str(output_path),
                'platform': platform,
                'title': title,
                'url': url
            }
            
        except subprocess.TimeoutExpired:
            raise Exception("ä¸‹è½½è¶…æ—¶ (è¶…è¿‡10åˆ†é’Ÿ)")
        except FileNotFoundError:
            raise Exception("yt-dlp æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install yt-dlp")
        except Exception as e:
            raise Exception(f"ä¸‹è½½å¤±è´¥: {str(e)}")
    
    def _get_title(self, url: str) -> Optional[str]:
        """è·å–è§†é¢‘æ ‡é¢˜"""
        try:
            cmd = [
                get_yt_dlp_path(),
                '--get-title',
                '--no-download',
                url
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            if result.returncode == 0:
                title = result.stdout.strip()
                # æ¸…ç†æ ‡é¢˜ä¸­çš„éæ³•æ–‡ä»¶åå­—ç¬¦
                title = re.sub(r'[<>:"/\\|?*]', '_', title)
                return title[:100]  # é™åˆ¶é•¿åº¦
        except:
            pass
        return None
    
    def cleanup(self, audio_path: str):
        """åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶"""
        try:
            if os.path.exists(audio_path):
                os.remove(audio_path)
                print(f"ğŸ—‘ï¸ å·²æ¸…ç†: {audio_path}")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†å¤±è´¥: {e}")

    def scrape_xiaohongshu(self, url: str) -> Dict:
        """
        æŠ“å–å°çº¢ä¹¦å›¾æ–‡ç¬”è®°å†…å®¹
        
        Args:
            url: å°çº¢ä¹¦é“¾æ¥
            
        Returns:
            åŒ…å«æ ‡é¢˜ã€æè¿°ã€å›¾ç‰‡ã€è¯„è®ºçš„å­—å…¸
        """
        print("ğŸ“ æœªæ£€æµ‹åˆ°è§†é¢‘ï¼Œå°è¯•æŠ“å–å›¾æ–‡å†…å®¹...")
        
        # å°è¯•æ–¹æ³•1: ç”¨ yt-dlp --dump-json è·å–å…ƒæ•°æ®
        try:
            yt_dlp = get_yt_dlp_path()
            cmd = [yt_dlp, '--dump-json', '--no-download', url]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0 and result.stdout.strip():
                data = json.loads(result.stdout.strip())
                
                title = data.get('title', '')
                description = data.get('description', '') or data.get('title', '')
                uploader = data.get('uploader', 'æœªçŸ¥ä½œè€…')
                
                # å°è¯•è·å–å›¾ç‰‡
                images = []
                if 'thumbnails' in data:
                    for thumb in data.get('thumbnails', []):
                        if 'url' in thumb:
                            images.append(thumb['url'])
                
                result_dict = {
                    'type': 'image_text',
                    'title': title or description[:50] or 'å°çº¢ä¹¦ç¬”è®°',
                    'description': description,
                    'author': uploader,
                    'images': images,
                    'comments': [],
                    'url': url
                }
                
                print(f"âœ… å›¾æ–‡æŠ“å–æˆåŠŸ(yt-dlp): {result_dict['title']}")
                return result_dict
        except Exception as e:
            print(f"âš ï¸ yt-dlp æ–¹æ³•å¤±è´¥: {e}")
        
        # å°è¯•æ–¹æ³•2: ç›´æ¥è¯·æ±‚ç½‘é¡µè§£æ
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': 'text/html,application/xhtml+xml',
            }
            response = requests.get(url, headers=headers, timeout=30)
            
            # ä» HTML ä¸­æå– JSON æ•°æ®
            json_match = re.search(r'window\.__INITIAL_STATE__\s*=\s*(\{.*?\});', response.text, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(1))
                # è§£æ note æ•°æ®...
                print("âœ… å›¾æ–‡æŠ“å–æˆåŠŸ(ç½‘é¡µè§£æ)")
        except Exception as e:
            print(f"âš ï¸ ç½‘é¡µè§£æå¤±è´¥: {e}")
        
        raise Exception("å›¾æ–‡æŠ“å–å¤±è´¥ï¼Œè¯·å°è¯•æä¾›è§†é¢‘é“¾æ¥")
    
    def download_or_scrape(self, url: str, force: bool = False) -> Dict:
        """
        ä¸‹è½½è§†é¢‘ï¼Œå¤±è´¥åˆ™æŠ“å–å›¾æ–‡
        
        Args:
            url: é“¾æ¥
            force: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
            
        Returns:
            åŒ…å«éŸ³é¢‘è·¯å¾„æˆ–å›¾æ–‡å†…å®¹çš„å­—å…¸
        """
        platform = self.detect_platform(url)
        
        # å°çº¢ä¹¦ï¼šå…ˆå°è¯•è·å–å…ƒæ•°æ®ï¼Œåˆ¤æ–­æ˜¯è§†é¢‘è¿˜æ˜¯å›¾æ–‡
        if platform == 'Xiaohongshu':
            # å…ˆç”¨ --dump-json è·å–ä¿¡æ¯ï¼Œåˆ¤æ–­å†…å®¹ç±»å‹
            try:
                result = self._get_xiaohongshu_info(url)
                if result.get('has_video', True):
                    # æœ‰è§†é¢‘ï¼Œç”¨æ™®é€šä¸‹è½½
                    return self.download(url, force)
                else:
                    # æ— è§†é¢‘ï¼Œè¿”å›å›¾æ–‡å†…å®¹
                    print("ğŸ“ æ£€æµ‹ä¸ºå›¾æ–‡ç¬”è®°")
                    return result
            except Exception as e:
                print(f"âš ï¸ å…ƒæ•°æ®è·å–å¤±è´¥: {e}ï¼Œå°è¯•ç›´æ¥ä¸‹è½½...")
                try:
                    return self.download(url, force)
                except:
                    # ä¸‹è½½å¤±è´¥ï¼Œå°è¯•æŠ“å–å›¾æ–‡
                    print("ğŸ’¡ å°è¯•æŠ“å–å›¾æ–‡å†…å®¹...")
                    return self.scrape_xiaohongshu(url)
        
        # X (Twitter)ï¼šå…ˆå°è¯•ä¸‹è½½ï¼Œå¤±è´¥åˆ™æŠ“å–å›¾æ–‡
        if platform == 'X':
            try:
                return self.download(url, force)
            except Exception as e:
                error_msg = str(e)
                # æ£€æŸ¥æ˜¯å¦æ˜¯"æ²¡æœ‰è§†é¢‘"çš„é”™è¯¯
                if 'No video could be found' in error_msg or 'No media found' in error_msg:
                    print("ğŸ’¡ è¯¥å¸–å­æ²¡æœ‰è§†é¢‘ï¼Œå°è¯•æŠ“å–æ–‡å­—å’Œå›¾ç‰‡...")
                    return self.scrape_x_tweet(url)
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œä¹Ÿå°è¯•æŠ“å–å›¾æ–‡
                    print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {e}ï¼Œå°è¯•æŠ“å–å¸–å­å†…å®¹...")
                    try:
                        return self.scrape_x_tweet(url)
                    except:
                        raise  # å¦‚æœæŠ“å–ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºåŸé”™è¯¯
        
        # å…¶ä»–å¹³å°ç›´æ¥ä¸‹è½½
        return self.download(url, force)
    
    def _get_xiaohongshu_info(self, url: str) -> Dict:
        """è·å–å°çº¢ä¹¦ç¬”è®°ä¿¡æ¯ï¼ˆåˆ¤æ–­æ˜¯å¦æœ‰è§†é¢‘ï¼‰"""
        yt_dlp = get_yt_dlp_path()
        cmd = [yt_dlp, '--dump-json', '--no-download', '--skip-download', url]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

        if result.returncode == 0 and result.stdout.strip():
            data = json.loads(result.stdout.strip())

            title = data.get('title', '')
            description = data.get('description', '') or data.get('title', '')
            uploader = data.get('uploader', 'æœªçŸ¥ä½œè€…')

            # åˆ¤æ–­æ˜¯å¦æœ‰è§†é¢‘æµ
            has_video = bool(data.get('formats')) or data.get('duration', 0) > 0

            # è·å–å›¾ç‰‡
            images = []
            for thumb in data.get('thumbnails', []):
                if 'url' in thumb:
                    images.append(thumb['url'])

            return {
                'type': 'image_text',
                'has_video': has_video,
                'title': title or description[:50] or 'å°çº¢ä¹¦ç¬”è®°',
                'description': description,
                'author': uploader,
                'images': images,
                'comments': [],
                'url': url
            }

        raise Exception("æ— æ³•è·å–ç¬”è®°ä¿¡æ¯")

    def scrape_x_tweet(self, url: str) -> Dict:
        """
        æŠ“å– X (Twitter) å¸–å­å†…å®¹ï¼ˆæ–‡å­— + å›¾ç‰‡ï¼‰
        
        Args:
            url: X å¸–å­é“¾æ¥
            
        Returns:
            åŒ…å«æ–‡å­—å†…å®¹ã€å›¾ç‰‡çš„å­—å…¸
        """
        print("ğŸ“ æ£€æµ‹ä¸º X å¸–å­ï¼Œå°è¯•æŠ“å–å†…å®¹...")
        
        # æå– tweet ID å’Œç”¨æˆ·å
        tweet_id_match = re.search(r'/(?:status|i)/(\d+)', url)
        username_match = re.search(r'x\.com/([^/]+)/status', url)
        
        tweet_id = tweet_id_match.group(1) if tweet_id_match else None
        username = username_match.group(1) if username_match else None
        
        # æ–¹æ³•1: å°è¯• vxtwitter.com API (æœ€ç®€å•å¯é )
        if tweet_id and username:
            try:
                print(f"ğŸ”„ å°è¯• vxtwitter API...")
                vx_url = f"https://api.vxtwitter.com/{username}/status/{tweet_id}"
                response = requests.get(vx_url, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    description = data.get('text', '')
                    if description:
                        # è·å–å›¾ç‰‡
                        images = data.get('media_urls', [])
                        result_dict = {
                            'type': 'image_text',
                            'title': description[:50] or 'X å¸–å­',
                            'description': description,
                            'author': data.get('user_name', username),
                            'images': images,
                            'comments': [],
                            'url': url
                        }
                        print(f"âœ… X å¸–å­æŠ“å–æˆåŠŸ: {result_dict['title']}")
                        return result_dict
            except Exception as e:
                print(f"âš ï¸ vxtwitter å¤±è´¥: {e}")
        
        # æ–¹æ³•2: å°è¯• fxtwitter.com API
        if tweet_id and username:
            try:
                print(f"ğŸ”„ å°è¯• fxtwitter API...")
                fx_url = f"https://api.fxtwitter.com/{username}/status/{tweet_id}"
                response = requests.get(fx_url, timeout=30)
                if response.status_code == 200:
                    data = response.json()
                    tweet_data = data.get('tweet', {})
                    description = tweet_data.get('text', '')
                    if description:
                        # è·å–åª’ä½“
                        images = []
                        media = tweet_data.get('media', [])
                        for m in media:
                            if m.get('type') == 'photo':
                                images.append(m.get('url', ''))
                        
                        result_dict = {
                            'type': 'image_text',
                            'title': description[:50] or 'X å¸–å­',
                            'description': description,
                            'author': tweet_data.get('author', {}).get('name', username),
                            'images': images,
                            'comments': [],
                            'url': url
                        }
                        print(f"âœ… X å¸–å­æŠ“å–æˆåŠŸ(fxtwitter): {result_dict['title']}")
                        return result_dict
            except Exception as e:
                print(f"âš ï¸ fxtwitter å¤±è´¥: {e}")
        
        raise Exception("X å¸–å­æŠ“å–å¤±è´¥ï¼Œè¯·ç¡®è®¤ç½‘ç»œèƒ½è®¿é—® X")


if __name__ == "__main__":
    # æµ‹è¯•ä¸‹è½½
    downloader = VideoDownloader()
    
    # æµ‹è¯• URL
    test_url = "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
    
    try:
        result = downloader.download(test_url)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
