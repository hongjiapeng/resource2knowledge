# ğŸŒ Resource2Knowledge - äº’è”ç½‘èµ„æºçŸ¥è¯†å…¥åº“å·¥ä½œæµ

> æœ¬åœ°è¿è¡Œã€æ— éœ€ä»˜è´¹ APIã€é€‚é… 8GB æ˜¾å­˜ï¼ˆå½“å‰æ”¯æŒè§†é¢‘ï¼Œåç»­å¯æ‰©å±•å›¾æ–‡ï¼‰

## ğŸ“‹ åŠŸèƒ½æ¦‚è§ˆ

| æ­¥éª¤ | æ¨¡å— | æŠ€æœ¯ | æ˜¾å­˜å ç”¨ |
|------|------|------|----------|
| 1. ä¸‹è½½éŸ³é¢‘ | downloader.py | yt-dlp | - |
| 2. è¯­éŸ³è½¬æ–‡æœ¬ | transcriber.py | faster-whisper small | ~2GB |
| 3. ç”Ÿæˆæ‘˜è¦ | summarizer.py | Ollama qwen2.5:7b | ~4-5GB |
| 4. å…¥åº“ | notion_writer.py | Notion API | - |

**æ€»æ˜¾å­˜å ç”¨**: ~6-7GB (ä¸²è¡Œæ‰§è¡Œï¼Œä¸å¹¶å‘)

---



## ğŸ¯ é¡¹ç›®å®šä½

å°†äº’è”ç½‘ä¸Šçš„å†…å®¹èµ„æºæ²‰æ·€ä¸ºå¯æ£€ç´¢çš„ä¸ªäººçŸ¥è¯†åº“ã€‚

- **å½“å‰è¾“å…¥**: è§†é¢‘é“¾æ¥ï¼ˆå¦‚ YouTubeã€Bilibiliï¼‰
- **åç»­è¾“å…¥è§„åˆ’**: å›¾æ–‡å†…å®¹ï¼ˆå¦‚å°çº¢ä¹¦å›¾æ–‡ï¼‰
- **å½“å‰è¾“å‡º**: Notion æ•°æ®åº“
- **åç»­è¾“å‡ºè§„åˆ’**: CSV / Excel ç­‰ç¦»çº¿æ ¼å¼

---
## ğŸ–¥ï¸ ç¯å¢ƒè¦æ±‚

- **OS**: Windows 11
- **GPU**: NVIDIA RTX 5060 (8GB VRAM)
- **RAM**: 32GB
- **CUDA**: 12.x

---

## ğŸ“¦ å®‰è£…æ­¥éª¤

### 1. åŸºç¡€ç¯å¢ƒ

```powershell
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir resource2knowledge
cd resource2knowledge

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
python -m venv venv
.\venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. å®‰è£… yt-dlp

```powershell
# æ–¹æ³•1: pip
pip install yt-dlp

# æ–¹æ³•2: winget (Windows)
winget install yt-dlp
```

### 3. å®‰è£… FFmpeg (Bç«™ç­‰éœ€è¦)

```powershell
# winget
winget install FFmpeg.FFmpeg

# æˆ–æ‰‹åŠ¨ä¸‹è½½: https://ffmpeg.org/download.html
# å°† ffmpeg.exe æ·»åŠ åˆ° PATH
```

### 4. å®‰è£… Ollama

```powershell
# ä¸‹è½½: https://ollama.com/download/windows
# æˆ–ä½¿ç”¨ winget
winget install Ollama.Ollama

# å¯åŠ¨æœåŠ¡ (åå°è¿è¡Œ)
ollama serve

# æ‹‰å–æ¨¡å‹
ollama pull qwen2.5:7b-instruct-q4_K_M

# éªŒè¯
ollama list
```

### 5. ä¸‹è½½ Whisper æ¨¡å‹

é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½ `small` æ¨¡å‹ (~500MB)

---

## âš™ï¸ é…ç½® Notion

### æ­¥éª¤ 1: åˆ›å»º Integration

1. è®¿é—® https://www.notion.so/my-integrations
2. ç‚¹å‡» **New integration**
3. åç§°: `Resource2Knowledge`
4. è·å– **Internal Integration Token**

### æ­¥éª¤ 2: åˆ›å»ºæ•°æ®åº“

åˆ›å»º Notion æ•°æ®åº“ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µ:

| å­—æ®µå | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| Title | æ ‡é¢˜ | è§†é¢‘æ ‡é¢˜ |
| URL | URL | è§†é¢‘é“¾æ¥ |
| Platform | é€‰æ‹© | YouTube/Bilibili/... |
| Transcript | æ–‡æœ¬ | å®Œæ•´è½¬å½• |
| Summary | æ–‡æœ¬ | AI æ‘˜è¦ |
| Tags | å¤šé€‰ | è‡ªåŠ¨æ ‡ç­¾ |
| KeyPoints | æ–‡æœ¬ | è¦ç‚¹åˆ—è¡¨ |
| Category | é€‰æ‹© | è§†é¢‘åˆ†ç±» |
| Sentiment | é€‰æ‹© | positive/negative/neutral |
| CreatedTime | æ—¥æœŸ | åˆ›å»ºæ—¶é—´ |

### æ­¥éª¤ 3: åˆ†äº«æ•°æ®åº“ç»™ Integration

1. æ‰“å¼€ Notion æ•°æ®åº“é¡µé¢
2. ç‚¹å‡»å³ä¸Šè§’ `...` â†’ `Connections` â†’ æ·»åŠ  `Resource2Knowledge`

### æ­¥éª¤ 4: è·å– Database ID

```
https://notion.so/{workspace}/{Database_ID}?v=...
                      â†‘ è¿™é‡Œå°±æ˜¯ Database ID
```

### æ­¥éª¤ 5: é…ç½®ç¯å¢ƒå˜é‡

```powershell
# å¤åˆ¶é…ç½®æ¨¡æ¿
copy .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶
notepad .env
```

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### CLI åŸºæœ¬ç”¨æ³•

```powershell
# æ¿€æ´»ç¯å¢ƒ
.\venv\Scripts\activate

# è¿è¡Œå•ä¸ªè§†é¢‘
python main.py "https://www.youtube.com/watch?v=xxx"

# è°ƒè¯•æ¨¡å¼
python main.py "url" --log-level DEBUG

# è·³è¿‡éƒ¨åˆ†æ­¥éª¤
python main.py "url" --skip-summary
python main.py "url" --no-cleanup
```

### æ‰¹é‡å¤„ç†

```powershell
# åˆ›å»º URLs æ–‡ä»¶
@"
https://youtube.com/watch?v=xxx1
https://bilibili.com/video/xxx2
https://youtube.com/watch?v=xxx3
"@ | Out-File -Encoding utf8 urls.txt

# æ‰¹é‡å¤„ç†
Get-Content urls.txt | ForEach-Object { python main.py $_ }
```

---

## ğŸ” CUDA æ£€æŸ¥

```powershell
# æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"

# æ˜¾å­˜ä¿¡æ¯
python -c "import torch; print(f'VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')"
```

---

## ğŸ“Š æ˜¾å­˜å ç”¨é¢„ä¼°

| æ¨¡å‹ | å‚æ•°é‡ | é‡åŒ– | æ˜¾å­˜å ç”¨ | é€Ÿåº¦ |
|------|--------|------|----------|------|
| Whisper small | - | float16 | ~2GB | å¿« |
| qwen2.5:7b | 7B | Q4_K_M | ~4-5GB | ä¸­ç­‰ |
| **æ€»è®¡** | - | - | **~6-7GB** | 10åˆ†é’Ÿè§†é¢‘<3åˆ†é’Ÿ |

---

## ğŸ› å¸¸è§é—®é¢˜

### OOM è§£å†³æ–¹æ¡ˆ

1. **é™ä½æ¨¡å‹ç²¾åº¦**
   ```python
   # transcriber.py
   COMPUTE_TYPE = "int8"  # ä» float16 æ”¹ä¸º int8
   ```

2. **ä½¿ç”¨æ›´å°çš„ LLM**
   ```python
   # summarizer.py
   DEFAULT_MODEL = "llama3.2:3b-instruct-q4_K_M"  # ~2-3GB
   ```

3. **åˆ†æ‰¹å¤„ç†é•¿æ–‡æœ¬**
   ```python
   # æˆªæ–­è¿‡é•¿æ–‡æœ¬
   transcript = transcript[:3000]
   ```

4. **æ˜¾å¼é‡Šæ”¾æ˜¾å­˜**
   ```python
   import torch
   torch.cuda.empty_cache()
   del model
   gc.collect()
   ```

### å…¶ä»–é—®é¢˜

| é—®é¢˜ | è§£å†³æ–¹æ¡ˆ |
|------|----------|
| yt-dlp ä¸‹è½½å¤±è´¥ | æ£€æŸ¥ç½‘ç»œï¼Œæˆ–ä½¿ç”¨ä»£ç† |
| Whisper æŠ¥é”™ | ç¡®è®¤ FFmpeg å·²å®‰è£… |
| Ollama è¿æ¥å¤±è´¥ | è¿è¡Œ `ollama serve` |
| Notion 401 é”™è¯¯ | æ£€æŸ¥ Token å’Œ Database ID |

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
resource2knowledge/
â”œâ”€â”€ main.py              # ä¸»å…¥å£
â”œâ”€â”€ downloader.py        # è§†é¢‘ä¸‹è½½
â”œâ”€â”€ transcriber.py       # Whisper è½¬å½•
â”œâ”€â”€ summarizer.py       # LLM æ‘˜è¦
â”œâ”€â”€ notion_writer.py     # Notion å†™å…¥
â”œâ”€â”€ requirements.txt     # ä¾èµ–
â”œâ”€â”€ .env.example         # é…ç½®æ¨¡æ¿
â”œâ”€â”€ .env                 # æœ¬åœ°é…ç½® (gitignore)
â”œâ”€â”€ downloads/           # ä¸´æ—¶éŸ³é¢‘
â”œâ”€â”€ logs/                # è¿è¡Œæ—¥å¿—
â””â”€â”€ README.md
```

---

## ğŸ”§ ä¼˜åŒ–å»ºè®®

### é€Ÿåº¦ä¼˜åŒ–

1. **ä½¿ç”¨æ›´å¿«æ¨¡å‹**
   - Whisper: `base` (æ¯” small å¿«)
   - LLM: `phi3.5:3.8b-mini` (æ›´å¿«ä½†è´¨é‡ç•¥ä½)

2. **ç¼“å­˜æ¨¡å‹**
   - é¦–æ¬¡åŠ è½½åä¿æŒè¿è¡Œ

### è´¨é‡ä¼˜åŒ–

1. **ä½¿ç”¨æ›´å¤§æ¨¡å‹**
   - Whisper: `medium` (éœ€è¦æ›´å¤šæ˜¾å­˜)
   - LLM: `qwen2.5:14b` (éœ€è¦ 10GB+ æ˜¾å­˜)

---

## ğŸ“ License

MIT License - å¯è‡ªç”±ä½¿ç”¨å’Œä¿®æ”¹
